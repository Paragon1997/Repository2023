{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkwant\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import kwant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install qutip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge kwant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c pytorch pytorch-cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(60.).reshape(3, 4, 5)\n",
    "b = torch.arange(24.).reshape(4, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4400., 4730.],\n",
       "        [4532., 4874.],\n",
       "        [4664., 5018.],\n",
       "        [4796., 5162.],\n",
       "        [4928., 5306.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensordot(a, b, dims=([1, 0], [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = 16\n",
    "r = torch.rand((2,n_particles)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('active.all.allocated', 424),\n",
       "             ('active.all.current', 25),\n",
       "             ('active.all.freed', 399),\n",
       "             ('active.all.peak', 28),\n",
       "             ('active.large_pool.allocated', 58),\n",
       "             ('active.large_pool.current', 0),\n",
       "             ('active.large_pool.freed', 58),\n",
       "             ('active.large_pool.peak', 2),\n",
       "             ('active.small_pool.allocated', 366),\n",
       "             ('active.small_pool.current', 25),\n",
       "             ('active.small_pool.freed', 341),\n",
       "             ('active.small_pool.peak', 28),\n",
       "             ('active_bytes.all.allocated', 5193980928),\n",
       "             ('active_bytes.all.current', 590336),\n",
       "             ('active_bytes.all.freed', 5193390592),\n",
       "             ('active_bytes.all.peak', 2684945408),\n",
       "             ('active_bytes.large_pool.allocated', 5179965440),\n",
       "             ('active_bytes.large_pool.current', 0),\n",
       "             ('active_bytes.large_pool.freed', 5179965440),\n",
       "             ('active_bytes.large_pool.peak', 2684354560),\n",
       "             ('active_bytes.small_pool.allocated', 14015488),\n",
       "             ('active_bytes.small_pool.current', 590336),\n",
       "             ('active_bytes.small_pool.freed', 13425152),\n",
       "             ('active_bytes.small_pool.peak', 1246208),\n",
       "             ('allocated_bytes.all.allocated', 5193980928),\n",
       "             ('allocated_bytes.all.current', 590336),\n",
       "             ('allocated_bytes.all.freed', 5193390592),\n",
       "             ('allocated_bytes.all.peak', 2684945408),\n",
       "             ('allocated_bytes.large_pool.allocated', 5179965440),\n",
       "             ('allocated_bytes.large_pool.current', 0),\n",
       "             ('allocated_bytes.large_pool.freed', 5179965440),\n",
       "             ('allocated_bytes.large_pool.peak', 2684354560),\n",
       "             ('allocated_bytes.small_pool.allocated', 14015488),\n",
       "             ('allocated_bytes.small_pool.current', 590336),\n",
       "             ('allocated_bytes.small_pool.freed', 13425152),\n",
       "             ('allocated_bytes.small_pool.peak', 1246208),\n",
       "             ('allocation.all.allocated', 424),\n",
       "             ('allocation.all.current', 25),\n",
       "             ('allocation.all.freed', 399),\n",
       "             ('allocation.all.peak', 28),\n",
       "             ('allocation.large_pool.allocated', 58),\n",
       "             ('allocation.large_pool.current', 0),\n",
       "             ('allocation.large_pool.freed', 58),\n",
       "             ('allocation.large_pool.peak', 2),\n",
       "             ('allocation.small_pool.allocated', 366),\n",
       "             ('allocation.small_pool.current', 25),\n",
       "             ('allocation.small_pool.freed', 341),\n",
       "             ('allocation.small_pool.peak', 28),\n",
       "             ('inactive_split.all.allocated', 113),\n",
       "             ('inactive_split.all.current', 3),\n",
       "             ('inactive_split.all.freed', 110),\n",
       "             ('inactive_split.all.peak', 5),\n",
       "             ('inactive_split.large_pool.allocated', 28),\n",
       "             ('inactive_split.large_pool.current', 0),\n",
       "             ('inactive_split.large_pool.freed', 28),\n",
       "             ('inactive_split.large_pool.peak', 2),\n",
       "             ('inactive_split.small_pool.allocated', 85),\n",
       "             ('inactive_split.small_pool.current', 3),\n",
       "             ('inactive_split.small_pool.freed', 82),\n",
       "             ('inactive_split.small_pool.peak', 4),\n",
       "             ('inactive_split_bytes.all.allocated', 309123072),\n",
       "             ('inactive_split_bytes.all.current', 1506816),\n",
       "             ('inactive_split_bytes.all.freed', 307616256),\n",
       "             ('inactive_split_bytes.all.peak', 20971008),\n",
       "             ('inactive_split_bytes.large_pool.allocated', 293601280),\n",
       "             ('inactive_split_bytes.large_pool.current', 0),\n",
       "             ('inactive_split_bytes.large_pool.freed', 293601280),\n",
       "             ('inactive_split_bytes.large_pool.peak', 18874368),\n",
       "             ('inactive_split_bytes.small_pool.allocated', 15521792),\n",
       "             ('inactive_split_bytes.small_pool.current', 1506816),\n",
       "             ('inactive_split_bytes.small_pool.freed', 14014976),\n",
       "             ('inactive_split_bytes.small_pool.peak', 2096640),\n",
       "             ('max_split_size', -1),\n",
       "             ('num_alloc_retries', 1),\n",
       "             ('num_ooms', 1),\n",
       "             ('oversize_allocations.allocated', 0),\n",
       "             ('oversize_allocations.current', 0),\n",
       "             ('oversize_allocations.freed', 0),\n",
       "             ('oversize_allocations.peak', 0),\n",
       "             ('oversize_segments.allocated', 0),\n",
       "             ('oversize_segments.current', 0),\n",
       "             ('oversize_segments.freed', 0),\n",
       "             ('oversize_segments.peak', 0),\n",
       "             ('requested_bytes.all.allocated', 5193880634),\n",
       "             ('requested_bytes.all.current', 589856),\n",
       "             ('requested_bytes.all.freed', 5193290778),\n",
       "             ('requested_bytes.all.peak', 2684944448),\n",
       "             ('requested_bytes.large_pool.allocated', 5179965440),\n",
       "             ('requested_bytes.large_pool.current', 0),\n",
       "             ('requested_bytes.large_pool.freed', 5179965440),\n",
       "             ('requested_bytes.large_pool.peak', 2684354560),\n",
       "             ('requested_bytes.small_pool.allocated', 13915194),\n",
       "             ('requested_bytes.small_pool.current', 589856),\n",
       "             ('requested_bytes.small_pool.freed', 13325338),\n",
       "             ('requested_bytes.small_pool.peak', 1245248),\n",
       "             ('reserved_bytes.all.allocated', 2875195392),\n",
       "             ('reserved_bytes.all.current', 2149580800),\n",
       "             ('reserved_bytes.all.freed', 725614592),\n",
       "             ('reserved_bytes.all.peak', 2875195392),\n",
       "             ('reserved_bytes.large_pool.allocated', 2873098240),\n",
       "             ('reserved_bytes.large_pool.current', 2147483648),\n",
       "             ('reserved_bytes.large_pool.freed', 725614592),\n",
       "             ('reserved_bytes.large_pool.peak', 2873098240),\n",
       "             ('reserved_bytes.small_pool.allocated', 2097152),\n",
       "             ('reserved_bytes.small_pool.current', 2097152),\n",
       "             ('reserved_bytes.small_pool.freed', 0),\n",
       "             ('reserved_bytes.small_pool.peak', 2097152),\n",
       "             ('segment.all.allocated', 6),\n",
       "             ('segment.all.current', 2),\n",
       "             ('segment.all.freed', 4),\n",
       "             ('segment.all.peak', 6),\n",
       "             ('segment.large_pool.allocated', 5),\n",
       "             ('segment.large_pool.current', 1),\n",
       "             ('segment.large_pool.freed', 4),\n",
       "             ('segment.large_pool.peak', 5),\n",
       "             ('segment.small_pool.allocated', 1),\n",
       "             ('segment.small_pool.current', 1),\n",
       "             ('segment.small_pool.freed', 0),\n",
       "             ('segment.small_pool.peak', 1)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'max_split_size_mb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mmax_split_size_mb \n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'max_split_size_mb'"
     ]
    }
   ],
   "source": [
    "torch.cuda.max_split_size_mb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jordan_wigner_transform(j, lattice_length,device):\n",
    "    \"\"\"Jordan_wigner_transform(j, lattice_length). \n",
    "Defines the Jordan Wigner transformation for a 1D lattice.\"\"\"\n",
    "    operators = torch.tensor([[1,0],[0,-1]],device=device)\n",
    "    for _ in range(j-1): operators = torch.kron(operators, torch.tensor([[1,0],[0,-1]],device=device))\n",
    "    if j == 0: operators = torch.tensor([[0,0],[1,0]],device=device)\n",
    "    else: operators = torch.kron(operators, torch.tensor([[0,0],[1,0]],device=device))\n",
    "    for _ in range(lattice_length - j - 1): operators = torch.kron(operators, torch.tensor([[1,0],[0,1]],device=device))\n",
    "    return operators\n",
    "\n",
    "def Lorentzian(omega, Gamma, poles,device,Ed=-3/2,Sigma=3/2):\n",
    "    \"\"\"Lorentzian(omega, Gamma, poles,Ed=-3/2,Sigma=3/2). \n",
    "Defines the non-interacting DOS (rho0) and selects random sites based on the number of sites in the 1D lattice model and the calculated distribution.\"\"\"\n",
    "    return -(1/(omega-Ed-Sigma+1j*Gamma)).imag/np.pi, torch.tensor([Gamma * torch.tan(np.pi * (pi - 1 / 2))+Ed+Sigma for pi in torch.rand(poles)],device=device)\n",
    "\n",
    "def Startrans(poles,select,omega, eta,device,row=0):\n",
    "    \"\"\"Startrans(poles,select,row,omega, eta). \n",
    "Function to transform 1D lattice matrices in order to calculates parameters impengergy, bathenergy and Vkk from random sampling distribution.\"\"\"\n",
    "    Pbath,Dbath,pbar,G=torch.zeros(poles, poles,device=device),torch.zeros(poles,poles,device=device),torch.zeros(poles, poles,device=device),torch.zeros(len(omega),dtype = torch.cfloat,device=device)\n",
    "    for i in range(poles-1):\n",
    "        for j in range(poles-1):\n",
    "            if j>=i: Pbath[i+1][j+1]=-1/np.sqrt((poles-i-1)*(poles-i))\n",
    "        Pbath[i+1][i]=np.sqrt(poles-i-1)/np.sqrt(poles-i)\n",
    "    Pbath[row,:]=1/np.sqrt(poles)\n",
    "    for i, _ in enumerate(select): Dbath[i][i]=select[i]\n",
    "    pbar[1:,1:]=torch.linalg.eig(torch.mm(Pbath,torch.mm(Dbath,Pbath.T))[1:,1:])[1]\n",
    "    pbar[row][row]=1\n",
    "    for i, _ in enumerate(select): G+=1 / len(select) / (omega - select[i] + 1.j * eta)\n",
    "    return torch.mm(pbar.T,torch.mm(torch.mm(Pbath,torch.mm(Dbath,Pbath.T)),pbar)),G,select\n",
    "\n",
    "def HamiltonianAIM(c, impenergy, bathenergy, Vkk, U, Sigma, H0 = 0):\n",
    "    \"\"\"HamiltonianAIM(c, impenergy, bathenergy, Vkk, U, Sigma). \n",
    "Based on energy parameters calculates the Hamiltonian of a single-impurity system.\"\"\"\n",
    "    for i in range(2):\n",
    "        H0 += impenergy * (c[i].T * c[i])\n",
    "        for j, bathE in enumerate(bathenergy):\n",
    "            H0 += Vkk[j] * (c[i].T * c[2 * j + i + 2] + c[2 * j + i + 2].T * c[i])+ bathE * (c[2 * j + i + 2].T * c[2 * j + i + 2])\n",
    "    return H0,H0+U * (c[0].T * c[0] * c[1].T * c[1])-Sigma * (c[0].T * c[0] + c[1].T * c[1])\n",
    "\n",
    "def Constraint(ctype,H0,H,omega,eta,c,n,Tk,Nfin):\n",
    "    \"\"\"Constraint(ctype,H0,H,omega,eta,c,n). \n",
    "Constraint implementation function for DED method with various possible constraints.\"\"\"\n",
    "    if ctype[0]=='n':\n",
    "        vecs=torch.vstack((torch.linalg.eigh(H0)[1][:,0],torch.linalg.eigh(H)[1][:,0]))\n",
    "        exp=torch.conj(vecs)@n@vecs.T\n",
    "        print(exp[0,0],exp[1,1])\n",
    "        if ctype=='n' and np.round(exp[0,0])==np.round(exp[1,1]):\n",
    "            return MBGAIM(omega, H, c, eta,Tk,np.ones(len(Tk))),True\n",
    "        else:\n",
    "            return (np.zeros(len(omega),dtype = 'complex_'),np.zeros(len(Tk)),np.array([])),False\n",
    "    else:\n",
    "        return MBGAIM(omega, H, c, eta,Tk,np.ones(len(Tk))),True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m NewM,nonG,select\u001b[39m=\u001b[39mStartrans(poles,torch\u001b[39m.\u001b[39msort(Lorentzian(omega, Gamma, poles,device,Ed,Sigma)[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mvalues,omega,eta,device)\n\u001b[0;32m     19\u001b[0m H0,H\u001b[39m=\u001b[39mHamiltonianAIM(c,NewM[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],[NewM[k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m][k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(NewM)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)],NewM[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m:],U,Sigma)\n\u001b[1;32m---> 20\u001b[0m (MBGdat,Boltzmann,Ev0),reset\u001b[39m=\u001b[39mConstraint(ctype,H0,H,omega,eta,c,n,Tk,np\u001b[39m.\u001b[39;49marray([ar\u001b[39m<\u001b[39;49mN \u001b[39mfor\u001b[39;49;00m ar \u001b[39min\u001b[39;49;00m Nfin]))\n",
      "Cell \u001b[1;32mIn[118], line 45\u001b[0m, in \u001b[0;36mConstraint\u001b[1;34m(ctype, H0, H, omega, eta, c, n, Tk, Nfin)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m ctype[\u001b[39m0\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     44\u001b[0m     vecs\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mvstack((torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39meigh(H0)[\u001b[39m1\u001b[39m][:,\u001b[39m0\u001b[39m],torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39meigh(H)[\u001b[39m1\u001b[39m][:,\u001b[39m0\u001b[39m]))\n\u001b[1;32m---> 45\u001b[0m     exp\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mconj(vecs)\u001b[39m@n\u001b[39;49m\u001b[39m@vecs\u001b[39m\u001b[39m.\u001b[39mT\n\u001b[0;32m     46\u001b[0m     \u001b[39mprint\u001b[39m(exp[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],exp[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m])\n\u001b[0;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m ctype\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39mround(exp[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m])\u001b[39m==\u001b[39mnp\u001b[39m.\u001b[39mround(exp[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Float but found Long"
     ]
    }
   ],
   "source": [
    "U=3\n",
    "Ed=-3/2\n",
    "Sigma=3/2\n",
    "Gamma=0.3\n",
    "poles=6\n",
    "c=[Jordan_wigner_transform(i, 2*poles,device) for i in range(2*poles)]\n",
    "bound=3\n",
    "SizeO=1001\n",
    "etaco=[0.02,1e-39]\n",
    "omega= torch.linspace(-bound,bound,SizeO,device=device)\n",
    "eta=etaco[0]*abs(torch.linspace(-bound,bound,SizeO,device=device))+etaco[1]\n",
    "Tk=[0]\n",
    "Nfin=torch.zeros(len(Tk),dtype = torch.float)\n",
    "ctype='n'\n",
    "n=sum([c[i].T*c[i] for i in range(2*poles)])\n",
    "N=2000\n",
    "\n",
    "NewM,nonG,select=Startrans(poles,torch.sort(Lorentzian(omega, Gamma, poles,device,Ed,Sigma)[1]).values,omega,eta,device)\n",
    "H0,H=HamiltonianAIM(c,NewM[0][0],[NewM[k+1][k+1] for k in range(len(NewM)-1)],NewM[0,1:],U,Sigma)\n",
    "(MBGdat,Boltzmann,Ev0),reset=Constraint(ctype,H0,H,omega,eta,c,n,Tk,np.array([ar<N for ar in Nfin]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m poles\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m\n\u001b[1;32m----> 2\u001b[0m c\u001b[39m=\u001b[39m[Jordan_wigner_transform(i, \u001b[39m2\u001b[39m\u001b[39m*\u001b[39mpoles)\u001b[39m.\u001b[39mto_sparse() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mpoles)]\n",
      "Cell \u001b[1;32mIn[56], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m poles\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m\n\u001b[1;32m----> 2\u001b[0m c\u001b[39m=\u001b[39m[Jordan_wigner_transform(i, \u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49mpoles)\u001b[39m.\u001b[39mto_sparse() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mpoles)]\n",
      "Cell \u001b[1;32mIn[40], line 8\u001b[0m, in \u001b[0;36mJordan_wigner_transform\u001b[1;34m(j, lattice_length)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mif\u001b[39;00m j \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: operators \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m]])\n\u001b[0;32m      7\u001b[0m \u001b[39melse\u001b[39;00m: operators \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mkron(operators, torch\u001b[39m.\u001b[39mtensor([[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m]]))\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(lattice_length \u001b[39m-\u001b[39m j \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m): operators \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mkron(operators, torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m],[\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m]]))\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m operators\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "poles=8\n",
    "c=[Jordan_wigner_transform(i, 2*poles) for i in range(2*poles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(indices=tensor([[2048, 2049, 2050,  ..., 4093, 4094, 4095],\n",
       "                        [   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
       "        values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[1024, 1025, 1026,  ..., 4093, 4094, 4095],\n",
       "                        [   0,    1,    2,  ..., 3069, 3070, 3071]]),\n",
       "        values=tensor([ 1,  1,  1,  ..., -1, -1, -1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[ 512,  513,  514,  ..., 4093, 4094, 4095],\n",
       "                        [   0,    1,    2,  ..., 3581, 3582, 3583]]),\n",
       "        values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[ 256,  257,  258,  ..., 4093, 4094, 4095],\n",
       "                        [   0,    1,    2,  ..., 3837, 3838, 3839]]),\n",
       "        values=tensor([ 1,  1,  1,  ..., -1, -1, -1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[ 128,  129,  130,  ..., 4093, 4094, 4095],\n",
       "                        [   0,    1,    2,  ..., 3965, 3966, 3967]]),\n",
       "        values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[  64,   65,   66,  ..., 4093, 4094, 4095],\n",
       "                        [   0,    1,    2,  ..., 4029, 4030, 4031]]),\n",
       "        values=tensor([ 1,  1,  1,  ..., -1, -1, -1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[  32,   33,   34,  ..., 4093, 4094, 4095],\n",
       "                        [   0,    1,    2,  ..., 4061, 4062, 4063]]),\n",
       "        values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[  16,   17,   18,  ..., 4093, 4094, 4095],\n",
       "                        [   0,    1,    2,  ..., 4077, 4078, 4079]]),\n",
       "        values=tensor([ 1,  1,  1,  ..., -1, -1, -1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[   8,    9,   10,  ..., 4093, 4094, 4095],\n",
       "                        [   0,    1,    2,  ..., 4085, 4086, 4087]]),\n",
       "        values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[   4,    5,    6,  ..., 4093, 4094, 4095],\n",
       "                        [   0,    1,    2,  ..., 4089, 4090, 4091]]),\n",
       "        values=tensor([ 1,  1,  1,  ..., -1, -1, -1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[   2,    3,    6,  ..., 4091, 4094, 4095],\n",
       "                        [   0,    1,    4,  ..., 4089, 4092, 4093]]),\n",
       "        values=tensor([ 1,  1, -1,  ..., -1,  1,  1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo),\n",
       " tensor(indices=tensor([[   1,    3,    5,  ..., 4091, 4093, 4095],\n",
       "                        [   0,    2,    4,  ..., 4090, 4092, 4094]]),\n",
       "        values=tensor([ 1, -1, -1,  ...,  1,  1, -1]),\n",
       "        size=(4096, 4096), nnz=2048, layout=torch.sparse_coo)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "crow_indices = [0, 1, 2]\n",
    "col_indices = [0,1]\n",
    "values = [1,-1]\n",
    "csr=torch.sparse_csr_tensor(torch.tensor(crow_indices, dtype=torch.int64),torch.tensor(col_indices, dtype=torch.int64),torch.tensor(values), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, -1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,0],[0,-1]])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  0,  0,  0],\n",
       "        [ 0, -1,  0,  0],\n",
       "        [ 0,  0, -1,  0],\n",
       "        [ 0,  0,  0,  1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmaz=torch.tensor([[1,0],[0,-1]])\n",
    "torch.kron(sigmaz, sigmaz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "(Batch element 0) last value of crow_indices should be equal to the length of col_indices.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49msparse_csr_tensor(torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mint64),torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mint64),torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m1\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: (Batch element 0) last value of crow_indices should be equal to the length of col_indices."
     ]
    }
   ],
   "source": [
    "torch.sparse_csr_tensor(torch.tensor([0,2,2], dtype=torch.int64),torch.tensor([0,1], dtype=torch.int64),torch.tensor([1,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.,  1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.,  9.],\n",
       "          [10., 11., 12., 13., 14.],\n",
       "          [15., 16., 17., 18., 19.]],\n",
       " \n",
       "         [[20., 21., 22., 23., 24.],\n",
       "          [25., 26., 27., 28., 29.],\n",
       "          [30., 31., 32., 33., 34.],\n",
       "          [35., 36., 37., 38., 39.]],\n",
       " \n",
       "         [[40., 41., 42., 43., 44.],\n",
       "          [45., 46., 47., 48., 49.],\n",
       "          [50., 51., 52., 53., 54.],\n",
       "          [55., 56., 57., 58., 59.]]]),\n",
       " tensor([[[ 0.,  1.],\n",
       "          [ 2.,  3.],\n",
       "          [ 4.,  5.]],\n",
       " \n",
       "         [[ 6.,  7.],\n",
       "          [ 8.,  9.],\n",
       "          [10., 11.]],\n",
       " \n",
       "         [[12., 13.],\n",
       "          [14., 15.],\n",
       "          [16., 17.]],\n",
       " \n",
       "         [[18., 19.],\n",
       "          [20., 21.],\n",
       "          [22., 23.]]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
